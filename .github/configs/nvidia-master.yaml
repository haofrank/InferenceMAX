dsr1-fp4-b200-dynamo-trt:
  image: nvcr.io/nvidia/ai-dynamo/tensorrtllm-runtime:0.8.1.post1
  model: deepseek-r1-fp4
  model-prefix: dsr1
  runner: b200-multinode-slurm
  precision: fp4
  framework: dynamo-trt
  multinode: true
  disagg: true
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - spec-decoding: "mtp"
      conc-list: [1214]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen2_dep8_batch64_eplb0_mtp2.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen2_dep8_batch64_eplb0_mtp2.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [875]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen5_dep8_batch16_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen5_dep8_batch16_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [6]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen5_tep8_batch1_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen5_tep8_batch1_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [10, 15, 25, 45, 90, 180]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen5_tep8_batch32_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/mtp/ctx1_gen5_tep8_batch32_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [ 4968 ]
      prefill:
        num-worker: 3
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/mtp/ctx3_gen4_dep8_batch128_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/mtp/ctx3_gen4_dep8_batch128_eplb0_mtp1.yaml"
      decode:
        num-worker: 4
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [10860]
      prefill:
        num-worker: 3
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/mtp/ctx3_gen5_dep4_batch512_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/mtp/ctx3_gen5_dep4_batch512_eplb0_mtp1.yaml"
      decode:
        num-worker: 5
        tp: 4
        ep: 4
        dp-attn: true

    # Non-MTP configurations
    - conc-list: [4096]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen1_dep8_batch512_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen1_dep8_batch512_eplb0_mtp0.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [2192]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen2_dep8_batch128_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen2_dep8_batch128_eplb0_mtp0.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [1365]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen5_dep8_batch32_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen5_dep8_batch32_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [6]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen5_tep8_batch1_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen5_tep8_batch1_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [10, 15, 25, 45, 90, 180]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen5_tep8_batch32_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen5_tep8_batch32_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [450]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen6_tep8_batch64_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/1k1k/stp/ctx1_gen6_tep8_batch64_eplb0_mtp0.yaml"
      decode:
        num-worker: 6
        tp: 8
        ep: 8
        dp-attn: false

  - isl: 8192
    osl: 1024
    search-space:
    - spec-decoding: "mtp"
      conc-list: [90]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen1_dep8_batch8_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen1_dep8_batch8_eplb0_mtp3.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [66]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen3_tep8_batch16_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen3_tep8_batch16_eplb0_mtp3.yaml"
      decode:
        num-worker: 3
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [6]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen5_tep8_batch1_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen5_tep8_batch1_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [10, 15, 30, 60]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen5_tep8_batch8_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx1_gen5_tep8_batch8_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [548]
      prefill:
        num-worker: 3
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx3_gen1_dep8_batch64_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx3_gen1_dep8_batch64_eplb0_mtp3.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [1096, 1691]
      prefill:
        num-worker: 5
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx5_gen1_dep8_batch192_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx5_gen1_dep8_batch192_eplb0_mtp1.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [658]
      prefill:
        num-worker: 5
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/mtp/ctx5_gen2_dep8_batch32_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/mtp/ctx5_gen2_dep8_batch32_eplb0_mtp3.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true

    # Non-MTP configurations
    - conc-list: [6]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/stp/ctx1_gen5_tep8_batch1_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/stp/ctx1_gen5_tep8_batch1_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [10, 15, 25, 50, 100]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/stp/ctx1_gen5_tep8_batch8_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/stp/ctx1_gen5_tep8_batch8_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [370]
      prefill:
        num-worker: 2
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/stp/ctx2_gen5_tep8_batch64_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/stp/ctx2_gen5_tep8_batch64_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [1606]
      prefill:
        num-worker: 4
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/stp/ctx4_gen1_dep8_batch192_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/stp/ctx4_gen1_dep8_batch192_eplb0_mtp0.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [837]
      prefill:
        num-worker: 4
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/stp/ctx4_gen3_dep8_batch32_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/stp/ctx4_gen3_dep8_batch32_eplb0_mtp0.yaml"
      decode:
        num-worker: 3
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [2222]
      prefill:
        num-worker: 7
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b200-fp4/8k1k/stp/ctx7_gen2_dep8_batch128_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b200-fp4/8k1k/stp/ctx7_gen2_dep8_batch128_eplb0_mtp0.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true

dsr1-fp4-b300-dynamo-trt:
  image: nvcr.io/nvidia/ai-dynamo/tensorrtllm-runtime:0.8.1.post1
  model: deepseek-r1-fp4
  model-prefix: dsr1
  runner: b300
  precision: fp4
  framework: dynamo-trt
  multinode: true
  disagg: true
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - spec-decoding: "mtp"
      conc-list: [654]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen1_dep8_batch64_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen1_dep8_batch64_eplb0_mtp3.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [271]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen2_dep8_batch16_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen2_dep8_batch16_eplb0_mtp3.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [11]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen5_tep8_batch1_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen5_tep8_batch1_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [10, 20, 25, 60, 120, 200]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen5_tep8_batch32_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx1_gen5_tep8_batch32_eplb0_mtp3.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [2342]
      prefill:
        num-worker: 2
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx2_gen1_dep8_batch256_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx2_gen1_dep8_batch256_eplb0_mtp1.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [8609]
      prefill:
        num-worker: 5
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx5_gen2_dep8_batch512_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx5_gen2_dep8_batch512_eplb0_mtp1.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [12926]
      prefill:
        num-worker: 5
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/mtp/ctx5_gen2_dep8_batch768_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/mtp/ctx5_gen2_dep8_batch768_eplb0_mtp1.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true

    # Non-MTP configurations
    - conc-list: [1176]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen2_dep8_batch64_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen2_dep8_batch64_eplb0_mtp0.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [6]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen4_tep8_batch1_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen4_tep8_batch1_eplb0_mtp0.yaml"
      decode:
        num-worker: 4
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [5, 10, 15, 25]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen5_tep4_batch4_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen5_tep4_batch4_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 4
        ep: 4
        dp-attn: false
    - conc-list: [60, 110, 195, 395]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen5_tep8_batch64_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx1_gen5_tep8_batch64_eplb0_mtp0.yaml"
      decode:
        num-worker: 5
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [4405]
      prefill:
        num-worker: 2
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx2_gen1_dep8_batch512_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx2_gen1_dep8_batch512_eplb0_mtp0.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [8192]
      prefill:
        num-worker: 3
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx3_gen1_dep8_batch1024_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx3_gen1_dep8_batch1024_eplb0_mtp0.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [4611]
      prefill:
        num-worker: 3
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/1k1k/stp/ctx3_gen2_dep8_batch256_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/1k1k/stp/ctx3_gen2_dep8_batch256_eplb0_mtp0.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true

  - isl: 8192
    osl: 1024
    search-space:
    - spec-decoding: "mtp"
      conc-list: [2198]
      prefill:
        num-worker: 10
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/mtp/ctx10_gen1_dep8_batch256_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/mtp/ctx10_gen1_dep8_batch256_eplb0_mtp1.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [52]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/mtp/ctx1_gen4_tep4_batch8_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/mtp/ctx1_gen4_tep4_batch8_eplb0_mtp3.yaml"
      decode:
        num-worker: 4
        tp: 4
        ep: 4
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [8]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/mtp/ctx1_gen4_tep8_batch1_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/mtp/ctx1_gen4_tep8_batch1_eplb0_mtp3.yaml"
      decode:
        num-worker: 4
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [32]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/mtp/ctx1_gen4_tep8_batch4_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/mtp/ctx1_gen4_tep8_batch4_eplb0_mtp3.yaml"
      decode:
        num-worker: 4
        tp: 8
        ep: 8
        dp-attn: false
    - spec-decoding: "mtp"
      conc-list: [181]
      prefill:
        num-worker: 3
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/mtp/ctx3_gen1_dep8_batch16_eplb0_mtp3.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/mtp/ctx3_gen1_dep8_batch16_eplb0_mtp3.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - spec-decoding: "mtp"
      conc-list: [1197]
      prefill:
        num-worker: 9
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/mtp/ctx9_gen1_dep8_batch128_eplb0_mtp1.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/mtp/ctx9_gen1_dep8_batch128_eplb0_mtp1.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true

    # Non-MTP configurations
    - conc-list: [105]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen3_tep4_batch32_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen3_tep4_batch32_eplb0_mtp0.yaml"
      decode:
        num-worker: 3
        tp: 4
        ep: 4
        dp-attn: false
    - conc-list: [63]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen3_tep8_batch16_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen3_tep8_batch16_eplb0_mtp0.yaml"
      decode:
        num-worker: 3
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [4]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen3_tep8_batch1_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen3_tep8_batch1_eplb0_mtp0.yaml"
      decode:
        num-worker: 3
        tp: 8
        ep: 8
        dp-attn: false
    - conc-list: [12]
      prefill:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen4_tep4_batch2_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx1_gen4_tep4_batch2_eplb0_mtp0.yaml"
      decode:
        num-worker: 4
        tp: 4
        ep: 4
        dp-attn: false
    - conc-list: [589]
      prefill:
        num-worker: 5
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx5_gen2_dep8_batch32_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx5_gen2_dep8_batch32_eplb0_mtp0.yaml"
      decode:
        num-worker: 2
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [1093]
      prefill:
        num-worker: 6
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx6_gen1_dep8_batch128_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx6_gen1_dep8_batch128_eplb0_mtp0.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
    - conc-list: [2048]
      prefill:
        num-worker: 8
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        # https://github.com/ishandhanani/srt-slurm/blob/sa-submission-q1-2026/recipes/trtllm/b300-fp4/8k1k/stp/ctx8_gen1_dep8_batch256_eplb0_mtp0.yaml
        - "CONFIG_FILE=recipes/trtllm/b300-fp4/8k1k/stp/ctx8_gen1_dep8_batch256_eplb0_mtp0.yaml"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true

dsr1-fp4-b200-sglang:
  image: lmsysorg/sglang:v0.5.6-cu129-amd64
  model: nvidia/DeepSeek-R1-0528-FP4-V2
  model-prefix: dsr1
  runner: b200
  precision: fp4
  framework: sglang
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 4, ep: 4, conc-start: 4, conc-end: 128 }
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 128 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 4, ep: 4, conc-start: 4, conc-end: 128 }
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 128 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 4, ep: 4, conc-start: 4, conc-end: 128 }
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 16 }

dsr1-fp4-b200-trt:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post2
  model: nvidia/DeepSeek-R1-0528-FP4-V2
  model-prefix: dsr1
  runner: b200-trt
  precision: fp4
  framework: trt
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    # If TP=4, 
    #   If CONC > 32, then EP=4
    #   If CONC >= 256, DP_ATTN=true
    - { tp: 4, conc-start: 4, conc-end: 32 }
    - { tp: 4, ep: 4, conc-start: 64, conc-end: 128 }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 256, conc-end: 256 }
    # If TP=8, 
    #   If CONC > 8, then EP=8
    #   If CONC >= 256, DP_ATTN=true
    - { tp: 8, conc-start: 4, conc-end: 8 }
    - { tp: 8, ep: 8, conc-start: 16, conc-end: 128 }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 256, conc-end: 256 }
  - isl: 1024
    osl: 8192
    search-space:
    # If TP=4, 
    #   If CONC > 32, then EP=4
    #   If CONC >= 256, DP_ATTN=true
    - { tp: 4, conc-start: 4, conc-end: 32 }
    - { tp: 4, ep: 4, conc-start: 64, conc-end: 128 }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 256, conc-end: 256 }
    # If TP=8, 
    #   If CONC > 16, then EP=8
    #   If CONC >= 256, DP_ATTN=true
    - { tp: 8, conc-start: 4, conc-end: 16 }
    - { tp: 8, ep: 8, conc-start: 32, conc-end: 128 }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 256, conc-end: 256 }
  - isl: 8192
    osl: 1024
    search-space:
    # If TP=4, 
    #   If CONC > 32, then EP=4 and DP_ATTN=true
    - { tp: 4, ep: 4, conc-start: 4, conc-end: 32 }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 64, conc-end: 256 }
    # If TP=8, 
    #   If CONC > 32, then EP=8 and DP_ATTN=true
    - { tp: 8, conc-start: 4, conc-end: 32 }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 64, conc-end: 256 }

dsr1-fp4-b200-trt-mtp:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post2
  model: nvidia/DeepSeek-R1-0528-FP4-V2
  model-prefix: dsr1
  runner: b200-trt
  precision: fp4
  framework: trt
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    # If TP=4:
    #   If CONC >= 16, then EP=4
    #   If CONC >= 128, DP_ATTN=true, MOE_BACKEND=CUTLASS, MTP=1
    - { tp: 4, conc-start: 4, conc-end: 8, spec-decoding: mtp }
    - { tp: 4, ep: 4, conc-start: 16, conc-end: 64, spec-decoding: mtp }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 128, conc-end: 256, spec-decoding: mtp }
    # If TP=8:
    #   If CONC >= 16, then EP=8
    #   If CONC >= 64, DP_ATTN=true, MOE_BACKEND=CUTLASS, MTP=1
    - { tp: 8, conc-start: 4, conc-end: 8, spec-decoding: mtp }
    - { tp: 8, ep: 8, conc-start: 16, conc-end: 32, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 64, conc-end: 256, spec-decoding: mtp }
  - isl: 1024
    osl: 8192
    search-space:
    # If TP=4:
    #   If CONC >= 32, then EP=4
    #   If CONC >= 128, DP_ATTN=true, MOE_BACKEND=CUTLASS, MTP=1
    - { tp: 4, conc-start: 4, conc-end: 16, spec-decoding: mtp }
    - { tp: 4, ep: 4, conc-start: 32, conc-end: 64, spec-decoding: mtp }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 128, conc-end: 256, spec-decoding: mtp }
    # If TP=8:
    #   If CONC >= 8, then EP=8
    #   If CONC >= 128, DP_ATTN=true, MOE_BACKEND=CUTLASS, MTP=1
    - { tp: 8, conc-start: 4, conc-end: 4, spec-decoding: mtp }
    - { tp: 8, ep: 8, conc-start: 8, conc-end: 64, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 128, conc-end: 256, spec-decoding: mtp }
  - isl: 8192
    osl: 1024
    search-space:
    # If TP=4:
    #   If CONC >= 32, then EP=4, DP_ATTN=true, MOE_BACKEND=CUTLASS, MTP=1
    - { tp: 4, conc-start: 4, conc-end: 16, spec-decoding: mtp }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 32, conc-end: 256, spec-decoding: mtp }
    # If TP=8:
    #   If CONC >= 32, then EP=8, DP_ATTN=true, MOE_BACKEND=CUTLASS, MTP=1
    - { tp: 8, conc-start: 4, conc-end: 16, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 32, conc-end: 256, spec-decoding: mtp }

dsr1-fp8-b200-sglang:
  image: lmsysorg/sglang:v0.5.6-cu129-amd64
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: b200
  precision: fp8
  framework: sglang
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 8, ep: 1, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 8, ep: 1, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 8, ep: 1, conc-start: 4, conc-end: 4 }
    - { tp: 4, ep: 1, conc-start: 4, conc-end: 32 }

dsr1-fp8-b200-trt:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.2.0rc6.post2
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: b200-trt
  precision: fp8
  framework: trt
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 8, ep: 1, conc-start: 64, conc-end: 128 }
    - { tp: 4, ep: 1, conc-start: 8, conc-end: 16 } 
    - { tp: 8, ep: 1, conc-start: 4, conc-end: 8 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 256, conc-end: 256}
    - { tp: 8, ep: 1, conc-start: 4, conc-end: 128 }    
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 8, ep: 1, conc-start: 64, conc-end: 256 }
    - { tp: 4, ep: 1, conc-start: 8, conc-end: 32 }
    - { tp: 8, ep: 1, conc-start: 4, conc-end: 8 }

dsr1-fp8-b200-trt-mtp:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post2
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: b200-trt
  precision: fp8
  framework: trt
  multinode: false
  seq-len-configs:
  # For all sequence lengths, EP=TP, MOE_BACKEND=DEEPGEMM, MTP=3 (or MTP=1 when DP_ATTN=true)
  - isl: 1024
    osl: 1024
    search-space:
    # If CONC >= 64, then DP_ATTN=true, MTP=1
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 32, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 64, conc-end: 256, spec-decoding: mtp }
  - isl: 1024
    osl: 8192
    search-space:
    # If CONC >= 128, then DP_ATTN=true, MTP=1
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 128, conc-end: 256, spec-decoding: mtp }
  - isl: 8192
    osl: 1024
    search-space:
    # If CONC >= 64, then DP_ATTN=true, MTP=1
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 32, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 64, conc-end: 256, spec-decoding: mtp }

dsr1-fp8-h200-sglang:
  image: lmsysorg/sglang:v0.5.7-cu129-amd64
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: h200
  precision: fp8
  framework: sglang
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 8, conc-start: 4, conc-end: 64 }

dsr1-fp8-h200-trt:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post2
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: h200
  precision: fp8
  framework: trt
  multinode: false
  # For all sequence lengths, EP=TP
  seq-len-configs:
  - isl: 1024
    osl: 1024
    # If CONC > 64, then DP_ATTN=true
    search-space:
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    # If CONC > 64, then DP_ATTN=true
    search-space:
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    # If CONC > 32, then DP_ATTN=true
    search-space:
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 32 }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 64, conc-end: 64 }

dsr1-fp8-h200-trt-mtp:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post2
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: h200
  precision: fp8
  framework: trt
  multinode: false
  # For all sequence lengths, EP=TP, MOE_BACKEND=CUTLASS, MTP=3 (or MTP=1 when DP_ATTN=true)
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    # If CONC >= 128, then DP_ATTN=true, MTP=1
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 128, conc-end: 256, spec-decoding: mtp }
  - isl: 1024
    osl: 8192
    search-space:
    # If CONC >= 256, then DP_ATTN=true, MTP=1
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 128, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 256, conc-end: 256, spec-decoding: mtp }
  - isl: 8192
    osl: 1024
    search-space:
    # If CONC >= 64, then DP_ATTN=true, MTP=1
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 32, spec-decoding: mtp }
    - { tp: 8, ep: 8, dp-attn: true, conc-start: 64, conc-end: 256, spec-decoding: mtp }

gptoss-fp4-b200-trt:
  image: nvcr.io#nvidia/tensorrt-llm/release:1.2.0rc2
  model: openai/gpt-oss-120b
  model-prefix: gptoss
  runner: b200-trt
  precision: fp4
  framework: trt
  multinode: false
  seq-len-configs:
  # DP Attn at higher concurrencies, TP attn at middle to lower. TP=1 turns out to be highest as artifact of concurrency limit=128
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 128, conc-end: 128 }
    - { tp: 2, ep: 2, dp-attn: true, conc-start: 64, conc-end: 128 }
    - { tp: 4, ep: 4, dp-attn: true, conc-start: 64, conc-end: 64 }
    - { tp: 2, conc-start: 8, conc-end: 32 }
    - { tp: 4, conc-start: 4, conc-end: 16 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 2, ep: 2, dp-attn: true, conc-start: 64, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 16 }
    - { tp: 4, conc-start: 4, conc-end: 128 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  # DP Attn at higher concurrencies, TP attn at middle to lower. TP=1 turns out to be highest as artifact of concurrency limit=128
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 128, conc-end: 128 }
    - { tp: 2, ep: 2, dp-attn: true, conc-start: 64, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 32 }
    - { tp: 8, conc-start: 4, conc-end: 8 }

gptoss-fp4-b200-vllm:
  image: vllm/vllm-openai:v0.13.0
  model: openai/gpt-oss-120b
  model-prefix: gptoss
  runner: b200
  precision: fp4
  framework: vllm
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 4 }

gptoss-fp4-h100-vllm:
  image: vllm/vllm-openai:v0.13.0
  model: openai/gpt-oss-120b
  model-prefix: gptoss
  runner: h100
  precision: fp4
  framework: vllm
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 2, conc-start: 4, conc-end: 64 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 2, conc-start: 4, conc-end: 64 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 2, conc-start: 4, conc-end: 64 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 16 }

gptoss-fp4-h200-trt:
  image: nvcr.io#nvidia/tensorrt-llm/release:gpt-oss-dev
  model: openai/gpt-oss-120b
  model-prefix: gptoss
  runner: h200
  precision: fp4
  framework: trt
  multinode: false
  # For all sequence lengths, EP=TP, DP_ATTENTION=false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 1, ep: 1, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 2, ep: 2, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 4, ep: 4, dp-attn: false, conc-start: 4, conc-end: 32 }
    - { tp: 8, ep: 8, dp-attn: false, conc-start: 4, conc-end: 8 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 1, ep: 1, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 2, ep: 2, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 4, ep: 4, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 8, ep: 8, dp-attn: false, conc-start: 4, conc-end: 8 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 1, ep: 1, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 2, ep: 2, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 4, ep: 4, dp-attn: false, conc-start: 4, conc-end: 64 }
    - { tp: 8, ep: 8, dp-attn: false, conc-start: 4, conc-end: 8 }

gptoss-fp4-h200-vllm:
  image: vllm/vllm-openai:v0.13.0
  model: openai/gpt-oss-120b
  model-prefix: gptoss
  runner: h200
  precision: fp4
  framework: vllm
  multinode: false
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 4 }
    - { tp: 2, conc-start: 4, conc-end: 64 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 4 }
    - { tp: 2, conc-start: 4, conc-end: 64 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 64 }
    - { tp: 2, conc-start: 4, conc-end: 64 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 32 }

dsr1-fp4-gb200-dynamo-trt:
  image: nvcr.io#nvidia/ai-dynamo/tensorrtllm-runtime:0.5.1-rc0.pre3
  # Models are pre-downloaded to this path on GB200 runner to avoid repeated downloading
  model: /mnt/lustre01/models/deepseek-r1-0528-fp4-v2
  model-prefix: dsr1
  runner: gb200
  precision: fp4
  framework: dynamo-trt
  multinode: true
  disagg: true
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    # MTP configurations
    # tep - Run Tensor-Expert Parallel mode (attention_dp=false)
    # NOTE: Prefill tp and ep are always 4 because each GB200 node has 4 GPUs and
    # ctx_tp_size is hardcoded to 4 in launch_gb200-nv.sh. Decode tp/ep matches gen_tp_size.
    # For 1k/1k: prefill batch-size=4, max-num-tokens=4608
    - spec-decoding: "mtp"
      conc-list: [ 1, 2, 4, 8, 16, 36 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: false
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 4
        tp: 8
        ep: 8
        dp-attn: false
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=128"
        - "DECODE_MAX_BATCH_SIZE=32"
        - "DECODE_GPU_MEM_FRACTION=0.9"
        - "DECODE_MTP_SIZE=3"

    # dep - Run Data-Expert Parallel mode (attention_dp=true)
    - spec-decoding: "mtp"
      conc-list: [ 512, 1075 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=256"
        - "DECODE_MAX_BATCH_SIZE=64"
        - "DECODE_GPU_MEM_FRACTION=0.7"
        - "DECODE_MTP_SIZE=3"

    - spec-decoding: "mtp"
      conc-list: [ 2150 ]
      prefill:
        num-worker: 2
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=256"
        - "DECODE_MAX_BATCH_SIZE=128"
        - "DECODE_GPU_MEM_FRACTION=0.7"
        - "DECODE_MTP_SIZE=1"

    - spec-decoding: "mtp"
      conc-list: [ 512 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 32
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=64"
        - "DECODE_MAX_BATCH_SIZE=16"
        - "DECODE_GPU_MEM_FRACTION=0.6"
        - "DECODE_MTP_SIZE=3"

    - spec-decoding: "mtp"
      conc-list: [ 2252 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=512"
        - "DECODE_MAX_BATCH_SIZE=256"
        - "DECODE_GPU_MEM_FRACTION=0.8"
        - "DECODE_MTP_SIZE=1"

    # Non-MTP configurations (default spec_decoding="none")
    # tep - Run Tensor-Expert Parallel mode (attention_dp=false)
    - conc-list: [ 1, 2, 4, 8, 16, 32, 64, 141 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: false
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 4
        tp: 8
        ep: 8
        dp-attn: false
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=128"
        - "DECODE_MAX_BATCH_SIZE=128"
        - "DECODE_GPU_MEM_FRACTION=0.9"
        - "DECODE_MTP_SIZE=0"

    # dep - Run Data-Expert Parallel mode (attention_dp=true)
    - conc-list: [ 1075 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 32
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=32"
        - "DECODE_MAX_BATCH_SIZE=32"
        - "DECODE_GPU_MEM_FRACTION=0.7"
        - "DECODE_MTP_SIZE=0"

    - conc-list: [ 1075 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=64"
        - "DECODE_MAX_BATCH_SIZE=64"
        - "DECODE_GPU_MEM_FRACTION=0.75"
        - "DECODE_MTP_SIZE=0"

    - conc-list: [ 2048, 4300 ]
      prefill:
        num-worker: 2
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=256"
        - "DECODE_MAX_BATCH_SIZE=256"
        - "DECODE_GPU_MEM_FRACTION=0.75"
        - "DECODE_MTP_SIZE=0"

    - conc-list: [ 4300 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=4608"
        - "PREFILL_MAX_BATCH_SIZE=4"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=512"
        - "DECODE_MAX_BATCH_SIZE=512"
        - "DECODE_GPU_MEM_FRACTION=0.8"
        - "DECODE_MTP_SIZE=0"

  - isl: 8192
    osl: 1024
    search-space:
    # MTP configurations (spec_decoding="mtp")
    # tep - Run Tensor-Expert Parallel mode (attention_dp=false)
    # For 8k/1k: prefill batch-size=1, max-num-tokens=8448
    - spec-decoding: "mtp"
      conc-list: [ 1, 2, 4, 8, 18 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: false
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 3
        tp: 8
        ep: 8
        dp-attn: false
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=64"
        - "DECODE_MAX_BATCH_SIZE=16"
        - "DECODE_GPU_MEM_FRACTION=0.9"
        - "DECODE_MTP_SIZE=3"

    # dep - Run Data-Expert Parallel mode (attention_dp=true)
    - spec-decoding: "mtp"
      conc-list: [ 128, 269 ]
      prefill:
        num-worker: 5
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 32
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=32"
        - "DECODE_MAX_BATCH_SIZE=8"
        - "DECODE_GPU_MEM_FRACTION=0.7"
        - "DECODE_MTP_SIZE=3"

    - spec-decoding: "mtp"
      conc-list: [ 538 ]
      prefill:
        num-worker: 8
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 32
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=64"
        - "DECODE_MAX_BATCH_SIZE=16"
        - "DECODE_GPU_MEM_FRACTION=0.7"
        - "DECODE_MTP_SIZE=3"

    - spec-decoding: "mtp"
      conc-list: [ 1075 ]
      prefill:
        num-worker: 8
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=256"
        - "DECODE_MAX_BATCH_SIZE=64"
        - "DECODE_GPU_MEM_FRACTION=0.75"
        - "DECODE_MTP_SIZE=2"

    - spec-decoding: "mtp"
      conc-list: [ 2150 ]
      prefill:
        num-worker: 6
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=512"
        - "DECODE_MAX_BATCH_SIZE=256"
        - "DECODE_GPU_MEM_FRACTION=0.8"
        - "DECODE_MTP_SIZE=1"

    # Non-MTP configurations (default spec_decoding="none")
    # tep - Run Tensor-Expert Parallel mode (attention_dp=false)
    - conc-list: [ 1, 2, 4, 8, 16, 34 ]
      prefill:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: false
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 3
        tp: 8
        ep: 8
        dp-attn: false
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=32"
        - "DECODE_MAX_BATCH_SIZE=32"
        - "DECODE_GPU_MEM_FRACTION=0.9"
        - "DECODE_MTP_SIZE=0"

    # dep - Run Data-Expert Parallel mode (attention_dp=true)
    - conc-list: [ 256, 538 ]
      prefill:
        num-worker: 4
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 32
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=16"
        - "DECODE_MAX_BATCH_SIZE=16"
        - "DECODE_GPU_MEM_FRACTION=0.7"
        - "DECODE_MTP_SIZE=0"

    - conc-list: [ 1075 ]
      prefill:
        num-worker: 6
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=64"
        - "DECODE_MAX_BATCH_SIZE=64"
        - "DECODE_GPU_MEM_FRACTION=0.75"
        - "DECODE_MTP_SIZE=0"

    - conc-list: [ 2150 ]
      prefill:
        num-worker: 8
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 16
        ep: 16
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=128"
        - "DECODE_MAX_BATCH_SIZE=128"
        - "DECODE_GPU_MEM_FRACTION=0.75"
        - "DECODE_MTP_SIZE=0"

    - conc-list: [ 2150 ]
      prefill:
        num-worker: 5
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_MAX_NUM_TOKENS=8448"
        - "PREFILL_MAX_BATCH_SIZE=1"
      decode:
        num-worker: 1
        tp: 8
        ep: 8
        dp-attn: true
        additional-settings:
        - "DECODE_MAX_NUM_TOKENS=256"
        - "DECODE_MAX_BATCH_SIZE=256"
        - "DECODE_GPU_MEM_FRACTION=0.8"
        - "DECODE_MTP_SIZE=0"

dsr1-fp8-gb200-dynamo-sglang:
  image: lmsysorg/sglang:v0.5.5.post2
  # model: deepseek-ai/DeepSeek-R1-0528
  # Models are pre-downloaded to this path on GB200 runner to avoid repeated downloading
  model: /mnt/lustre01/models/deepseek-r1-0528
  model-prefix: dsr1
  runner: gb200
  precision: fp8
  framework: dynamo-sglang
  multinode: true
  disagg: true
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    # "Top of curve" (2 prefill workers each at DEP8 and 1 decode worker at DEP32)
    - spec-decoding: "none"
      conc-list: [ 4096 ]
      prefill:
        num-worker: 2
        # tp, ep, and dp-attn do nothing because they are hardcoded in the following file:
        # https://github.com/Elnifio/dynamo/blob/update-result-file-name/components/backends/sglang/slurm_jobs/scripts/gb200-fp8.sh
        tp: 1
        ep: 8
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=4"
        - "N_ADDITIONAL_FRONTENDS=9"
        - "SCRIPT_MODE=1k1k-max-tpt"
      decode:
        num-worker: 1
        tp: 1
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=8"

    # "Bottom of curve" (1 prefill worker at DEP4 and 4 decode workers at DEP4)
    - spec-decoding: "none"
      conc-list: [ 2, 4, 8, 16, 64, 128 ]
      prefill:
        num-worker: 1
        # tp, ep, and dp-attn do nothing because they are hardcoded in the following file:
        # https://github.com/Elnifio/dynamo/blob/update-result-file-name/components/backends/sglang/slurm_jobs/scripts/gb200-fp8.sh
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=1"
        - "N_ADDITIONAL_FRONTENDS=9"
        - "SCRIPT_MODE=1k1k-low-latency"
      decode:
        num-worker: 4
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=4"

    # "Middle of curve" (3 prefill workers each at DEP8 and 1 decode worker at DEP48)
    - spec-decoding: "none"
      conc-list: [ 1024, 2048, 4096 ]
      prefill:
        num-worker: 3
        # tp, ep, and dp-attn do nothing because they are hardcoded in the following file:
        # https://github.com/Elnifio/dynamo/blob/update-result-file-name/components/backends/sglang/slurm_jobs/scripts/gb200-fp8.sh
        tp: 1
        ep: 8
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=6"
        - "N_ADDITIONAL_FRONTENDS=9"
        - "SCRIPT_MODE=1k1k-max-tpt"
      decode:
        num-worker: 1
        tp: 1
        ep: 48
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=12"

  - isl: 8192
    osl: 1024
    search-space:
    # Low latency (1 prefill worker at DEP4 and 1 decode worker at DEP4)
    - spec-decoding: "none"
      conc-list: [ 4, 8, 16, 32 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=1"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=8k1k-low-latency"
      decode:
        num-worker: 1
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=1"

    # Middle and top of curve (5 prefill workers each at DEP8 and 1 decode worker at DEP32)
    - spec-decoding: "none"
      conc-list: [ 512, 1024, 2048, 6144 ]
      prefill:
        num-worker: 5
        tp: 1
        ep: 8
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=10"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=8k1k-max-tpt"
      decode:
        num-worker: 1
        tp: 1
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=8"

dsr1-fp4-gb200-dynamo-sglang:
  image: lmsysorg/sglang:v0.5.5.post2
  # TODO: what is the right name?
  # model: deepseek-ai/DeepSeek-R1-0528-fp4-v2
  # Models are pre-downloaded to this path on GB200 runner to avoid repeated downloading
  model: /mnt/lustre01/models/deepseek-r1-0528-fp4-v2
  model-prefix: dsr1
  runner: gb200
  precision: fp4
  framework: dynamo-sglang
  multinode: true
  disagg: true
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    # Low latency (1 prefill worker at DEP4 and 2 decode workers at DEP4)
    - spec-decoding: "none"
      conc-list: [ 4, 8, 32, 64 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=1"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=1k1k-low-latency"
      decode:
        num-worker: 2
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=2"

    # Mid curve (1 prefill worker at DEP4 and 1 decode workers at DEP48)
    - spec-decoding: "none"
      conc-list: [ 512, 1024, 2048, 4096, 8192 ]
      prefill:
        num-worker: 4
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=4"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=1k1k-middle-curve"
      decode:
        num-worker: 1
        tp: 1
        ep: 48
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=12"

    # Top of curve (1 prefill worker at DEP4 and 1 decode worker at DEP32)
    - spec-decoding: "none"
      conc-list: [ 8192, 12000, 15000 ]
      prefill:
        num-worker: 4
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=4"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=1k1k-max-tpt"
      decode:
        num-worker: 1
        tp: 1
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=8"
  - isl: 8192
    osl: 1024
    search-space:
    - spec-decoding: "none"
      conc-list: [ 4, 8, 32, 64 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 4
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=8k1k-low-latency"
      decode:
        num-worker: 4
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=4"
    - spec-decoding: "none"
      conc-list: [ 512, 1024, 2048, 4096 ]
      prefill:
        num-worker: 6
        tp: 1
        ep: 4
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=6"
        - "N_ADDITIONAL_FRONTENDS=9"
        - "SCRIPT_MODE=8k1k-middle-curve"
      decode:
        num-worker: 1
        tp: 1
        ep: 48
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=12"
    - spec-decoding: "none"
      conc-list: [ 1024, 2048, ]
      prefill:
        num-worker: 10
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=10"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=8k1k-max-tpt"
      decode:
        num-worker: 1
        tp: 1
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=8"
    - spec-decoding: "none"
      conc-list: [ 8192 ]
      prefill:
        num-worker: 10
        tp: 1
        ep: 4
        dp-attn: true
        additional-settings:
        - "PREFILL_NODES=10"
        - "N_ADDITIONAL_FRONTENDS=8"
        - "SCRIPT_MODE=8k1k-max-tpt"
      decode:
        num-worker: 1
        tp: 1
        ep: 32
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=8"

gptoss-fp4-gb200-dynamo-trt:
  image: nvcr.io#nvidia/ai-dynamo/tensorrtllm-runtime:0.7.0.post2
  model: openai/gpt-oss-120b
  model-prefix: gptoss
  runner: gb200
  precision: fp4
  framework: dynamo-trt
  multinode: true
  disagg: true
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    #Right of pareto
    #P: 1xTP1   D:1xTP4
    - spec-decoding: "none"
      conc-list: [ 1, 2, 4, 16, 32, 64, 128 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1
        tp: 4
        ep: 1
        dp-attn: false
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=256"
        - "DECODE_GPU_MEM_FRACTION=0.9"

# P: 1xTP1   D:4xTP2
    - spec-decoding: "none"
      conc-list: [ 16 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 4
        tp: 2
        ep: 1
        dp-attn: false
        additional-settings:
        - "DECODE_NODES=2"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=32"
        - "DECODE_GPU_MEM_FRACTION=0.9"

  # P: 1xTP1   D:1xDEP2
    - spec-decoding: "none"
      conc-list: [ 256, 512, 1024, 2048, 2560 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=1536"
        - "DECODE_GPU_MEM_FRACTION=0.9"

  # P: 1xTP1   D:2xDEP2
    - spec-decoding: "none"
      conc-list: [ 512, 1024, 2048, 2560 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 2
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=1536"
        - "DECODE_GPU_MEM_FRACTION=0.9"

  # P: 1xTP1   D:1xDEP4
    - spec-decoding: "none"
      conc-list: [ 256, 1024, 1536 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=512"
        - "DECODE_GPU_MEM_FRACTION=0.9"

# P: 1xTP1   D:3xDEP4
    - spec-decoding: "none"
      conc-list: [ 3072 ]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 3
        tp: 4
        ep: 4
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=1024"
        - "DECODE_GPU_MEM_FRACTION=0.9"

  - isl: 8192
    osl: 1024
    search-space:
    # Right side of pareto
    - spec-decoding: "none"
      conc-list: [1]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1  
        tp: 8
        ep: 1
        dp-attn: false
        additional-settings:
        - "DECODE_NODES=2"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=4"
        - "DECODE_GPU_MEM_FRACTION=0.9"

    - spec-decoding: "none"
      conc-list: [2, 4, 8, 16, 32, 64]
      prefill:
        num-worker: 1
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1  
        tp: 4
        ep: 1
        dp-attn: false
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=128"
        - "DECODE_GPU_MEM_FRACTION=0.9"

# Middle of pareto
# P: 2xTP1   D:1xTP4
    - spec-decoding: "none"
      conc-list: [128, 512]
      prefill:
        num-worker: 2
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1  
        tp: 4
        ep: 1
        dp-attn: false
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=1024"
        - "DECODE_GPU_MEM_FRACTION=0.9"

# P: 2xTP1   D:1xTP2
    - spec-decoding: "none"
      conc-list: [256, 384]
      prefill:
        num-worker: 2
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1  
        tp: 2
        ep: 1
        dp-attn: false
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=512"
        - "DECODE_GPU_MEM_FRACTION=0.9"

# P: 2xTP1   D:1xDEP2
    - spec-decoding: "none"
      conc-list: [128, 512]
      prefill:
        num-worker: 2
        tp: 1
        ep: 1
        dp-attn: false
        additional-settings:
        - "PREFILL_NODES=1"
        - "PREFILL_MAX_NUM_TOKENS=20000"
        - "PREFILL_MAX_BATCH_SIZE=32"
      decode:
        num-worker: 1
        tp: 2
        ep: 2
        dp-attn: true
        additional-settings:
        - "DECODE_NODES=1"
        - "DECODE_MAX_NUM_TOKENS=20000"
        - "DECODE_MAX_BATCH_SIZE=512"
        - "DECODE_GPU_MEM_FRACTION=0.9"
        